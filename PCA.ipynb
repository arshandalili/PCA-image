{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" font size = 5>\n",
    "<h1>\n",
    "<font size = 6>\n",
    "به‌نام خدا\n",
    "</h1>\n",
    "<h2>\n",
    "<font size = 6>\n",
    "پروژه PCA</h2>\n",
    "<h2>\n",
    "<font size = 6>\n",
    "ارشان دلیلی\n",
    "</h2>\n",
    "<h2>\n",
    "<font size = 6>\n",
    "شماره دانش‌جویی: ۹۸۱۰۵۷۵۱</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<h1>\n",
    "کد PCA\n",
    "</h1>\n",
    "<br>\n",
    "<font size=5>\n",
    "کد PCA را در پایین مشاهده می‌کنید. داریم: (توضیحات در پایین کد است.)\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def show_data(nparr):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(nparr[:, 0], nparr[:, 1], nparr[:, 2], c='b', marker='.')\n",
    "    ax.set_xlabel('Red')\n",
    "    ax.set_ylabel('Green')\n",
    "    ax.set_zlabel('Blue')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def eig_show_data(eigen_values, eigen_vectors):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.xlabel(\"Eigenvectors\")\n",
    "    plt.ylabel(\"Eigenvalues\")\n",
    "    plt.bar([str(i) for i in eigen_vectors], eigen_values, width=0.4)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def image_array(image_name):\n",
    "    filename = image_name\n",
    "    image = Image.open(filename)\n",
    "    width, height = image.size\n",
    "    npimage = np.array(image)\n",
    "    arr = []\n",
    "    for y in range(height - 1):\n",
    "        for x in range(width - 1):\n",
    "            arr.append(npimage[y, x])\n",
    "    nparr = np.array(arr, dtype=\"f\")\n",
    "    nparr = np.matrix.transpose(nparr)\n",
    "    return nparr, width, height\n",
    "\n",
    "\n",
    "def normalize_matrix(nparr):\n",
    "    return nparr - nparr.mean()\n",
    "\n",
    "\n",
    "def calc_covariance_element(x, y):\n",
    "    mean_x, mean_y = x.mean(), y.mean()\n",
    "    n = len(x)\n",
    "    return sum((x - mean_x) * (y - mean_y)) / n\n",
    "\n",
    "\n",
    "def covariance_matrix(data):\n",
    "    rows, cols = data.shape\n",
    "    cov_mat = np.zeros((cols, cols))\n",
    "    for i in range(cols):\n",
    "        for j in range(cols):\n",
    "            cov_mat[i][j] = calc_covariance_element(data[:, i], data[:, j])\n",
    "\n",
    "    return cov_mat\n",
    "\n",
    "\n",
    "def w_matrix(matrix):\n",
    "    eigvalues, eigvectors = np.linalg.eigh(matrix)\n",
    "    eig_show_data(eigvalues, eigvectors)\n",
    "    w1 = np.zeros([3, 1])\n",
    "    w2 = np.zeros([3, 1])\n",
    "    if np.argmin(eigvalues) == 0:\n",
    "        if eigvalues[1] >= eigvalues[2]:\n",
    "            w1 = eigvectors[1]\n",
    "            w2 = eigvectors[2]\n",
    "        else:\n",
    "            w1 = eigvectors[2]\n",
    "            w2 = eigvectors[1]\n",
    "    elif np.argmin(eigvalues) == 1:\n",
    "        if eigvalues[0] >= eigvalues[2]:\n",
    "            w1 = eigvectors[0]\n",
    "            w2 = eigvectors[2]\n",
    "        else:\n",
    "            w1 = eigvectors[2]\n",
    "            w2 = eigvectors[0]\n",
    "    else:\n",
    "        if eigvalues[0] >= eigvalues[1]:\n",
    "            w1 = eigvectors[0]\n",
    "            w2 = eigvectors[1]\n",
    "        else:\n",
    "            w1 = eigvectors[1]\n",
    "            w2 = eigvectors[0]\n",
    "\n",
    "    w = np.zeros((3, 2))\n",
    "    for i in range(3):\n",
    "        w[i, 0] = w1[i]\n",
    "    for i in range(3):\n",
    "        w[i, 1] = w2[i]\n",
    "    return w\n",
    "\n",
    "\n",
    "def output_image(data, img_height, img_width):\n",
    "    image_size = (img_height - 1) * (img_width - 1)\n",
    "    zero_matrix = np.zeros([image_size, 1])\n",
    "    hstack_matrix = np.hstack((data, zero_matrix))\n",
    "    new_image = Image.fromarray(np.reshape(hstack_matrix, (img_height - 1, img_width - 1, 3)).astype('uint8'))\n",
    "    new_image.save(\"out.jpg\")\n",
    "\n",
    "\n",
    "image_address = input(\"Enter address of the image file:\")\n",
    "nparr, width, height = image_array(image_address)\n",
    "show_data(np.matrix.transpose(nparr))\n",
    "nparrcov = nparr\n",
    "nparr = normalize_matrix(nparr)\n",
    "\n",
    "\"\"\"\n",
    "Calculate Covariance Matrix\n",
    "\"\"\"\n",
    "covariance = covariance_matrix(np.matrix.transpose(nparrcov))\n",
    "\n",
    "print(\"Covariance Matrix:\")\n",
    "print(covariance)\n",
    "\n",
    "\"\"\"\n",
    "Calculate W Matrix (Principal Components)\n",
    "\"\"\"\n",
    "w = w_matrix(covariance)\n",
    "print(\"W Matrix:\")\n",
    "print(w)\n",
    "\n",
    "\"\"\"\n",
    "Calculate final reduced data set\n",
    "\"\"\"\n",
    "reduce_data_matrix = np.matrix.transpose(np.dot(np.matrix.transpose(w), nparr))\n",
    "print(\"Reduced Data With PCA:\")\n",
    "print(reduce_data_matrix)\n",
    "\n",
    "\"\"\"\n",
    "Convert data to image\n",
    "\"\"\"\n",
    "output_image(reduce_data_matrix, height, width)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<br>\n",
    "<font size=5> ابتدا ماتریس حاصل از تصویر را normalized می‌کنیم سپس ماتریس کوواریانس آن را به‌دست می‌آوریم. در مرحله بعد ویژه‌مقدار و ویژه‌بردارهای ماتریس کوواریانس را حساب می‌کنیم و دو ویژه‌برداری که بیش‌ترین مقدار ویژه‌مقدار را دارند به عنوان Principal Component به‌ترتیب در ستون‌های اول و دوم ماتریس W قرار می‌دهیم. (محور و راستای این دو بردار بیش‌ترین واریانس یا معادلاً بیش‌ترین داده را دارد.) حال با ضرب ماتریس normalized در ماتریس W داده‌های جدید به‌دست می‌آیند که آن‌ها را به صورت عکس ذخیره می‌کنیم.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<br>\n",
    "<font size=5> حال به پرسش‌های مطرح‌شده پاسخ می‌دهیم:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<h1>\n",
    "الف-\n",
    "</h1>\n",
    "<br>\n",
    "    <strong>\n",
    "<font size=5> با توجه به کدی که برای PCA زدید، چرا ما بردارهای ویژه متناظر با ماکسیسمم مقادیر ویژه را برای انجام این پروسه در نظر می‌گیریم؟  \n",
    "    </strong>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<h1>\n",
    "پاسخ:</h1>\n",
    "<br>\n",
    "<font size=5> \n",
    "   در عملیات PCA سعی می‌شود تا با در نظر گرفتن واریانس داده‌ها، Principal Componentهایی به عنوان محور در نظر گرفته‌شوند که تا حد امکان بیش‌ترین مقادیر داده را در خود ذخیره کنند تا با کاهش بعد، تا حد امکان بیش‌ترین مقدار داده حفظ شود و داده‌های نسبتاً کمی از بین برود. در ماتریس کوواریانس، ویژه‌بردارها جهت محورهایی را نشان می‌دهند که بیش‌ترین واریانس را دارند یا معادلاً بیش‌تر داده‌ها در آن محور قرار دارند. (واریانس بیش‌تر یعنی بر روی خط و محور Principal Component داده‌های بیش‌تری وجود دارد.) هر کدام از ویژه‌بردارها یک Principal Component هستند که بر هم عمود می‌باشند و ویژه‌مقدار متناظر با این ویژه‌بردار نیز مقدار واریانس داده‌ها در محور ویژه‌بردار مذکور (که یک Principal Component است.) را نشان می‌دهد. بنابراین ویژه بردار متناظر با ویژه‌مقدار ماکسیمم تا حد ممکن بیش‌ترین مقدار داده‌ها را در محور خود دارد. سپس ویژه‌بردار متناظر با دومین ویژه‌مقدار بزرگ، بیش‌ترین واریانس و داده را در محور خود جای داده‌است و به همین ترتیب پیش می‌رود. در نتیجه با انتخاب ویژه‌بردارهای متناظر با ماکسیمم ویژه‌مقدارها تا جایی که ممکن است با کاهش بعد بیش‌ترین حجم از داده‌ها باقی می‌ماند و داده‌های نسبتاً کمی از بین می‌رود در حالی که بعد کاهش می‌یابد. \n",
    "   </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<h1>\n",
    "ب-\n",
    "</h1>\n",
    "<br>\n",
    "    <strong>\n",
    "<font size=5> چرا هرچه تعداد بردار ویژه‌های بیش‌تری نگه داریم، عکسمان نیز با کیفیت‌تر می‌شود؟  \n",
    "    </strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<h1>\n",
    "پاسخ:</h1>\n",
    "<br>\n",
    "<font size=5> همان‌طور که در پاسخ (الف) اشاره شد، اگر به‌ترتیب ویژه‌بردارهای متناظر با ماکسیمم ویژه‌مقدارها را انتخاب کنیم آن‌گاه بخش بیش‌تری از داده‌ها را حفظ خواهیم کرد و می‌دانیم که ویژه‌بردارها بر هم متعامدند. در نتیجه هر چه‌قدر ویژه‌بردارهای بیش‌تری انتخاب کنیم، داده بیش‌تری نگهداری خواهیم کرد و کیفیت تصویر کم‌تر افت می‌کند. (البته همان‌طور که اشاره شد بخش زیادی از داده‌ها در Principal Componentهای اولیه وجود دارد و Principal Componentهای بعدی سهم کم‌تری در داده‌ها دارند ولی بدیهتاً وجود آن‌ها موجب افزایش کیفیت تصویر حاصل می‌شود.) \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<h1>\n",
    "ج-\n",
    "</h1>\n",
    "<br>\n",
    "    <strong>\n",
    "<font size=5> راجع‌به نحوه ذخیره هویت افراد/عکس‌ها در هنگام تشخیص چهره تحقیق کنید (امتیازی) \n",
    "    </strong>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<h1>\n",
    "پاسخ:</h1>\n",
    "<br>\n",
    "<font size=5>\n",
    "    با استفاده از PCA می‌توانیم Principal Componentهای مهم تصویر را به‌دست آورده و ذخیره کنیم و این‌کار را برای تصاویری که با استفاده از آن‌ها قصد تشخیص چهره داریم انجام می‌دهیم. با این کار می‌توانیم eigenfaceها (بردار تصاویر اولیه) را به دست آوریم. (eigenface در مقاله Face Recognition Using Eigenfaces اثر M.A. Turk and A.P. Pentland به‌طور مفصل توضیح داده شده‌است.) سپس تصویری که می‌خواهیم بررسی کنیم (برای تشخیص چهره) را بر روی face space تصویر می‌کنیم به‌طوری که مولفه‌های آن eigenfaceهای نمونه تصاویر اولیه هستند و هر چه‌قدر ضرایب هر کدام از eigenfaceها بیش‌تر باشد، آن‌گاه می‌توان گفت که ورودی به تصویر مرتبط با آن eigenface شبیه‌تر است و اگر اختلاف آن‌ها از حد معینی کم‌تر باشد، می‌توان با تقریب خوبی ادعا کرد که این تصویر (یا چهره) همان تصویر (یا چهره) ورودی متناظر با آن eigenface است و این‌گونه تشخیص چهره را انجام داد. (منبع این بررسی، مقاله Face Recognition using Principle Component Analysis  اثر Kyungnam Kim است.)\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<br>\n",
    "<font size=5> در انتها به عنوان مثال نمودارهای RGB و مقادیر ویژه و بردارهای ویژه نمونه را بررسی می‌کنیم. داریم:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](Results/2/in.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<br>\n",
    "<font size=5> حال نمودار RGB را برای نمونه تصویر به‌دست می‌آوریم. داریم: \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](Results/2/RGB_Data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<br>\n",
    "<font size=5> سپس نمودار ویژه‌بردار و ویژه‌مقدار را به‌دست می‌آوریم. داریم: \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](Results/2/Eigenvectors_and_Eigenvalues.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\">\n",
    "<br>\n",
    "<font size=5> حال برای خروجی نمونه و نمودار RGB تصویر حاصل داریم: \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](Results/2/out.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](Results/2/Output_RGB.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
